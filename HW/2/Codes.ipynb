{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def findProductInfo(dataSet, selectedProduct):\n",
    "    index = np.random.randint(1,498)\n",
    "    selectedProductPoint = 'Product ' + str(selectedProduct+1)\n",
    "    selectedProductCost = 'cost '+ str(selectedProduct+1)\n",
    "    return dataSet[selectedProductPoint][index], dataSet[selectedProductCost][index]\n",
    "\n",
    "\n",
    "def findProductValue(dataSet, selectedProduct):\n",
    "    productPoint, productCost = findProductInfo(dataSet, selectedProduct)\n",
    "    return (2.5 * productPoint - productCost)\n",
    "\n",
    "def isInInterval(interval, num):\n",
    "    if (num > interval[0]) and (num < interval[1]):\n",
    "        return True\n",
    "    elif (num == interval[0]) or (num == interval[1]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "class RLComp(object):\n",
    "    def __init__(self, __alpha, __beta, __policy, __policyPar, numArms, __dataSet):\n",
    "        self.numArms = numArms\n",
    "        self.alpha = __alpha\n",
    "        self.beta = __beta\n",
    "        self.policy = __policy\n",
    "        self.policyPar = __policyPar\n",
    "        self.numTrials = 0\n",
    "        self.numSelectedArms = [0] * numArms\n",
    "        self.sampleRewards = [0] * numArms\n",
    "        self.regret = []\n",
    "        self.avgRegret = []\n",
    "        self.prefArms = [0] * numArms\n",
    "        self.probArms = [0] * numArms\n",
    "        self.rBar = 0\n",
    "        self.dataSet = __dataSet\n",
    "\n",
    "        \n",
    "    def updateArmPref(self, selectedArm, armValue):\n",
    "        self.prefArms[selectedArm] = self.prefArms[selectedArm] + self.beta * (armValue - self.rBar)\n",
    "    \n",
    "    def updateRBar(self, armValue):\n",
    "        self.rBar = self.rBar + self.alpha * (armValue - self.rBar)\n",
    "        \n",
    "    def updateArmProbEGreedy(self):\n",
    "        ag = self.prefArms.index(max(self.prefArms))\n",
    "        self.probArms[ag] = 1 - self.policyPar + (self.policyPar/self.numArms)\n",
    "        \n",
    "        for i in range(self.numArms):\n",
    "            if not i == ag:\n",
    "                self.probArms[i] = self.policyPar/self.numArms\n",
    "                \n",
    "    def updateArmProbSoftMax(self):\n",
    "        p = self.prefArms\n",
    "        tou = self.policyPar\n",
    "        normalFactor = np.exp(p[0]/tou) + np.exp(p[1]/tou) + np.exp(p[2]/tou) + np.exp(p[3]/tou) + np.exp(p[4]/tou) + np.exp(p[5]/tou)\n",
    "\n",
    "        for i in range(self.numArms):\n",
    "            self.probArms[i] = np.exp(p[i]/tou)/normalFactor\n",
    "            \n",
    "    def updateArmProb(self):\n",
    "        if self.policy == 'ep-greedy':\n",
    "            self.updateArmProbEGreedy()\n",
    "        else:\n",
    "            self.updateArmProbSoftMax()\n",
    "        \n",
    "    def selectArm(self):\n",
    "        pi = self.probArms\n",
    "        arm1 = [0, pi[0]]\n",
    "        arm2 = [pi[0], pi[0]+pi[1]]\n",
    "        arm3 = [pi[0]+pi[1], pi[0]+pi[1]+pi[2]]\n",
    "        arm4 = [pi[0]+pi[1]+pi[2], pi[0]+pi[1]+pi[2]+pi[3]]\n",
    "        arm5 = [pi[0]+pi[1]+pi[2]+pi[3], pi[0]+pi[1]+pi[2]+pi[3]+pi[4]]\n",
    "        arm6 = [pi[0]+pi[1]+pi[2]+pi[3]+pi[4], pi[0]+pi[1]+pi[2]+pi[3]+pi[4]+pi[5]]\n",
    "\n",
    "        while True:\n",
    "            randomAction = np.random.uniform()\n",
    "            if isInInterval(arm1, randomAction):\n",
    "                self.numSelectedArms[0] = self.numSelectedArms[0] + 1\n",
    "                return 0\n",
    "            elif isInInterval(arm2, randomAction):\n",
    "                self.numSelectedArms[1] = self.numSelectedArms[1] + 1\n",
    "                return 1\n",
    "            elif isInInterval(arm3, randomAction):\n",
    "                self.numSelectedArms[2] = self.numSelectedArms[2] + 1\n",
    "                return 2\n",
    "            elif isInInterval(arm4, randomAction):\n",
    "                self.numSelectedArms[3] = self.numSelectedArms[3] + 1\n",
    "                return 3\n",
    "            elif isInInterval(arm5, randomAction):\n",
    "                self.numSelectedArms[4] = self.numSelectedArms[4] + 1\n",
    "                return 4\n",
    "            elif isInInterval(arm6, randomAction):\n",
    "                self.numSelectedArms[5] = self.numSelectedArms[5] + 1\n",
    "                return 5\n",
    "            \n",
    "    def setPolicyPar(self, numIter):\n",
    "        if self.policy == 'ep-greedy':\n",
    "            self.policyPar = 1/(numIter+1)\n",
    "        else:\n",
    "            self.policyPar = 100\n",
    "            \n",
    "    def updateSampleRewards(self, selectedArm, armValue):\n",
    "        self.sampleRewards[selectedArm] = self.sampleRewards[selectedArm] + armValue\n",
    "            \n",
    "    def calcAvgRegret(self, selectedArm):\n",
    "        miuStar = self.sampleRewards[selectedArm] / self.numSelectedArms[selectedArm]\n",
    "        temp = 0\n",
    "        for i in range(6):\n",
    "            if not self.numSelectedArms[i] == 0:\n",
    "                miuJ = self.sampleRewards[i]/self.numSelectedArms[i]\n",
    "                meanTJ = self.numSelectedArms[i]/self.numTrials\n",
    "                temp = temp + miuJ * meanTJ\n",
    "        \n",
    "        self.avgRegret.append(miuStar*self.numTrials - temp)\n",
    "        \n",
    "    def calcRegret(self, selectedArm):\n",
    "        miuStar = self.sampleRewards[selectedArm] / self.numSelectedArms[selectedArm]\n",
    "        self.regret.append(miuStar*self.numTrials - sum(self.sampleRewards))\n",
    "        \n",
    "    def findBestArm(self):\n",
    "        for j in range(100):\n",
    "            selectedArm = np.random.randint(0,self.numArms)\n",
    "            \n",
    "            for i in range(100):\n",
    "                self.numTrials = self.numTrials + 1\n",
    "                self.setPolicyPar(i)\n",
    "                self.updateArmProb()\n",
    "        \n",
    "                armValue = findProductValue(self.dataSet, selectedArm)\n",
    "                self.updateArmPref(selectedArm, armValue)\n",
    "                self.updateRBar(armValue)\n",
    "                self.updateSampleRewards(selectedArm, armValue)\n",
    "                selectedArm = self.selectArm()\n",
    "                \n",
    "                self.calcRegret(selectedArm)\n",
    "            self.calcAvgRegret(selectedArm)\n",
    "            if j == 0:   \n",
    "                print(\"In first episode best product is:\",selectedArm+1, '\\nWith regret:(the horizontal axis is n)')\n",
    "                plots = plt.plot([i for i in range(100)], self.regret)\n",
    "                plt.setp(plots, 'color', 'orchid')\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"In first episode best product is:\",selectedArm+1, '\\nWith regret:(the horizontal axis is ln(n))')\n",
    "                plots = plt.plot([np.log(i) for i in range(1,101)], self.regret)\n",
    "                plt.setp(plots, 'color', 'orchid')\n",
    "                plt.show()\n",
    "      \n",
    "        plot = plt.plot([np.log(i) for i in range(1,101)], self.avgRegret)\n",
    "        plt.setp(plot, 'color', 'orchid')\n",
    "        plt.show()\n",
    "\n",
    "        selected = self.numSelectedArms.index(max(self.numSelectedArms))\n",
    "        return ([selected+1])\n",
    "    \n",
    "dataSet = pd.read_csv(r'/home/atena/Desktop/ML/HW/2/Dataset.csv')    \n",
    "myAlgo = RLComp(0.1, 0.9, 'soft-max', 1, 6, dataSet)\n",
    "result = myAlgo.findBestArm()\n",
    "print('Best product is: ' ,result[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "taxiProp = ['Tap-Taxi', [0.1,5,3], 'Taxi-Nap', [0.3,2,2], 'Taxim', [0.7,1,1]]\n",
    "\n",
    "def wasteTimeCalc(noTaxiProb, meanWasteTime, varWasteTime):\n",
    "    findTaxiProb = np.random.uniform()\n",
    "    if (findTaxiProb < noTaxiProb) or (findTaxiProb == noTaxiProb):\n",
    "        return abs(np.random.normal(meanWasteTime, np.sqrt(varWasteTime), 1))\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def takeTaxi(sameTaxiProb, changeTaxiProb):\n",
    "    totalWastedTime = 0\n",
    "    selectedTaxi = np.random.randint(0,3)\n",
    "    taxiName = selectedTaxi * 2\n",
    "    allWastedTime = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        for j in range(1000):\n",
    "            wastedTime = wasteTimeCalc(taxiProp[taxiName+1][0], taxiProp[taxiName+1][1], taxiProp[taxiName+1][2])\n",
    "            totalWastedTime = totalWastedTime + wastedTime\n",
    "\n",
    "            if wastedTime == 0:\n",
    "                decisionProb = np.random.uniform() \n",
    "                if (decisionProb < sameTaxiProb) or (decisionProb == sameTaxiProb):\n",
    "                    taxiName = taxiName\n",
    "\n",
    "                else:\n",
    "                    dummy = taxiName\n",
    "                    while dummy == taxiName:\n",
    "                        selectedTaxi = np.random.randint(0,3)\n",
    "                        dummy = selectedTaxi * 2\n",
    "                    taxiName = dummy\n",
    "            else:\n",
    "                decisionProb = np.random.uniform()\n",
    "                if (decisionProb < changeTaxiProb) or (decisionProb == changeTaxiProb):\n",
    "                    dummy = taxiName\n",
    "                    while dummy == taxiName:\n",
    "                        selectedTaxi = np.random.randint(0,3)\n",
    "                        dummy = selectedTaxi * 2\n",
    "                    taxiName = dummy\n",
    "                else:\n",
    "                    taxiName = taxiName\n",
    "        allWastedTime.append(totalWastedTime)\n",
    "                \n",
    "    return (sum(allWastedTime)/10)[0]\n",
    "                \n",
    "\n",
    "\n",
    "print(\"Hercule Poirot's total wasted time is: \", takeTaxi(0.9, 0.9))\n",
    "print(\"Miss Marple's total wasted time is: \", takeTaxi(0.9, 0.2))\n",
    "print(\"Sherlock Holmes's total wasted time is: \", takeTaxi(0.3, 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class UCB2(object):\n",
    "    \n",
    "    def __init__(self, __alpha):\n",
    "        self.alpha = __alpha\n",
    "        self.pathsCount = [0] * 3\n",
    "        self.qValues = [0] * 3\n",
    "        self.pathsRetakeCount = [0] * 3\n",
    "        self.currPath = 0\n",
    "        self.allRetakes = 0\n",
    "    \n",
    "    def calcTou(self, path, increament):\n",
    "        return np.ceil( (1+self.alpha) ** (self.pathsRetakeCount[path]+increament) )\n",
    "\n",
    "    def calcBonus(self, path):\n",
    "        tou = self.calcTou(path, 0)\n",
    "        totalCount = sum(self.pathsCount)\n",
    "        return np.sqrt((1+self.alpha)*np.log(np.exp(1)* totalCount / tou)/(2*tou))\n",
    "    \n",
    "    def setPath(self, path):\n",
    "        self.currPath = path\n",
    "        self.pathsRetakeCount[path] = self.pathsRetakeCount[path] + 1\n",
    "        self.allRetakes = self.allRetakes + max(1, np.ceil(self.calcTou(path, 1) - self.calcTou(path, 0)))\n",
    "        \n",
    "    def setInitValue(self):\n",
    "        for i in range(3):\n",
    "            if self.pathsCount[i] == 0:\n",
    "                self.setPath(i)\n",
    "                return i\n",
    "            else:\n",
    "                return 4\n",
    "            \n",
    "    def endEpoch(self):\n",
    "        if self.allRetakes > sum(self.pathsCount):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def calcUtilityFunc(self):\n",
    "        utilityFunc = [0] * 3\n",
    "        for i in range(3):\n",
    "            bonus = self.calcBonus(i)\n",
    "            utilityFunc[i] = self.qValues[i] + bonus\n",
    "        return utilityFunc\n",
    "    \n",
    "    def selectPathUtilityFunc(self):\n",
    "        utilityFunc = self.calcUtilityFunc()\n",
    "        return utilityFunc.index(max(utilityFunc))\n",
    "\n",
    "    def choosePath(self):\n",
    "        selectedPath = self.setInitValue()\n",
    "        if selectedPath < 4:\n",
    "            return selectedPath\n",
    "        \n",
    "        selectedPath = self.currPath\n",
    "        if self.endEpoch():\n",
    "            return selectedPath\n",
    "        \n",
    "        selectedPath = self.selectPathUtilityFunc()\n",
    "        self.setPath(selectedPath)\n",
    "        return selectedPath\n",
    "    \n",
    "    def updateQValue(self, selectedPath, pathOutcome):\n",
    "        self.pathsCount[selectedPath] = self.pathsCount[selectedPath] + 1\n",
    "        self.qValues[selectedPath] = self.qValues[selectedPath] + (1/self.pathsCount[selectedPath]) * (pathOutcome - self.qValues[selectedPath])\n",
    "        return self.qValues[selectedPath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathOne():\n",
    "    cost = np.random.normal(2, np.sqrt(0.0625), 1)\n",
    "    delay = np.random.normal(0, np.sqrt(0.25), 1)\n",
    "    return cost, delay\n",
    "\n",
    "def pathTwo():\n",
    "    cost = np.random.normal(3.5, np.sqrt(0.25), 1)\n",
    "    delay = np.random.uniform(-3, 0.5)\n",
    "    return cost, delay\n",
    "\n",
    "def pathThree():\n",
    "    cost = np.random.uniform(3.5, 4.5)\n",
    "    delay = np.random.normal(-2.5, np.sqrt(0.25), 1)\n",
    "    return cost, delay\n",
    "\n",
    "def outcome(cost, delay):\n",
    "    if delay > 0 :\n",
    "        return (delay * 1.5 + cost)\n",
    "    elif delay < 0 : \n",
    "        return (cost + delay)\n",
    "\n",
    "def getOutcome(pathIndex):\n",
    "    cost = 0\n",
    "    delay = 0\n",
    "    if pathIndex == 0:\n",
    "        cost, delay = pathOne()\n",
    "    elif pathIndex == 1:\n",
    "        cost, delay = pathTwo()\n",
    "    elif pathIndex == 2:\n",
    "        cost, delay = pathThree()\n",
    "    else: \n",
    "        print('No outcome for this path!')\n",
    "    \n",
    "    return outcome(cost, delay)\n",
    "    \n",
    "def findBestWay():\n",
    "    alpha = [0.9, 0.5, 0.1, 0.01, 0.001]\n",
    "    pathsOutcomes = [0] * 3\n",
    "    allSelectedPaths = []\n",
    "    qValuesPath1 = []\n",
    "    qValuesPath2 = []\n",
    "    qValuesPath3 = []\n",
    "    for i in range(5):\n",
    "        myUCB = UCB2(alpha[i])\n",
    "        \n",
    "        for trial in range(10000):\n",
    "            selectedPath = myUCB.choosePath()\n",
    "            outcome = getOutcome(selectedPath)\n",
    "            pathsOutcomes[selectedPath] = outcome\n",
    "            qValue = myUCB.updateQValue(selectedPath, outcome)\n",
    "            \n",
    "            if selectedPath == 0:\n",
    "                qValuesPath1.append(qValue)\n",
    "            elif selectedPath == 1:\n",
    "                qValuesPath2.append(qValue)\n",
    "            elif selectedPath == 2:\n",
    "                qValuesPath3.append(qValue)\n",
    "                \n",
    "        allSelectedPaths.append(selectedPath+1)\n",
    "        \n",
    "        plotQ1, = plt.plot([i for i in range(len(qValuesPath1))], qValuesPath1)\n",
    "        plt.setp(plotQ1, 'color', 'orchid')\n",
    "        \n",
    "        plotQ2, = plt.plot([i for i in range(len(qValuesPath2))], qValuesPath2)\n",
    "        plt.setp(plotQ2, 'color', 'blue')\n",
    "        \n",
    "        plotQ3, = plt.plot([i for i in range(len(qValuesPath3))], qValuesPath3)\n",
    "        plt.setp(plotQ3, 'color', 'green')\n",
    "        \n",
    "        plt.title('Alpha is:' + str(alpha[i]))\n",
    "        plt.legend([plotQ1, plotQ2, plotQ3], ['Subway', 'Bus', 'Taxi'])\n",
    "        plt.show()\n",
    "    return allSelectedPaths\n",
    "\n",
    "\n",
    "print('Best path is:' ,findBestWay())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
